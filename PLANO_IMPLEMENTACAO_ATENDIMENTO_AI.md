# Plano de ImplementaÃ§Ã£o - Atendimento AI Estruturado

## ğŸ“‹ AnÃ¡lise da Ideia

### âœ… Ã‰ PossÃ­vel?
**SIM!** A implementaÃ§Ã£o Ã© totalmente viÃ¡vel e bem estruturada. Todos os componentes necessÃ¡rios jÃ¡ existem no projeto:

1. âœ… Modelo `AtendimentoAI` existe
2. âœ… Modelo `Contato` com campo `status` existe
3. âœ… ColeÃ§Ã£o `mensagens` com histÃ³rico completo existe
4. âœ… IntegraÃ§Ã£o com Ollama jÃ¡ funciona
5. âœ… Estrutura de banco de dados estÃ¡ pronta

### ğŸ¯ Objetivo
Criar um sistema de atendimento AI que:
- Usa prompts estruturados baseados no status do contato
- Analisa a conversa e sugere mudanÃ§as de status
- Retorna respostas contextuais e status sugerido em JSON
- MantÃ©m histÃ³rico completo para contexto

---

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

### Estrutura de Arquivos

```
src/lib/utils/
â”œâ”€â”€ generatePrompt.ts          # NOVO: GeraÃ§Ã£o do prompt estruturado
â”œâ”€â”€ ollama.ts                  # MODIFICAR: Suporte a resposta JSON
â””â”€â”€ saveSentMessage.ts         # JÃ EXISTE: Salvar mensagens enviadas

src/app/api/webhook/
â””â”€â”€ route.ts                   # MODIFICAR: Usar novo sistema de prompt
```

---

## ğŸ“ Componentes a Implementar

### 1. **Arquivo: `src/lib/utils/generatePrompt.ts`** (NOVO)

**Responsabilidades:**
- Buscar objeto `AtendimentoAI` do banco
- Buscar objeto `Contato` com status atual
- Buscar histÃ³rico de mensagens (Ãºltimas 10, mais recente primeiro)
- Montar prompt estruturado seguindo o formato especificado

**FunÃ§Ãµes principais:**

```typescript
interface GeneratePromptParams {
  contatoId: string;
  mensagemRecebida: string;
}

interface PromptResult {
  prompt: string;
  statusAtual: string;
}

export async function generatePrompt(params: GeneratePromptParams): Promise<PromptResult>
```

**Fluxo:**
1. Buscar `AtendimentoAI.findOne()` - obtÃ©m configuraÃ§Ã£o Ãºnica
2. Buscar `Contato.findById(contatoId)` - obtÃ©m status atual
3. Buscar `Mensagem.findOne({ contatoID: contatoId })` - obtÃ©m histÃ³rico
4. Montar prompt seguindo estrutura:
   ```
   {promptBase}
   
   Comportamento esperado para o status: {statusAtual}
   {objetoAtendimentoAI[statusAtual]}
   
   InstruÃ§Ãµes de anÃ¡lise...
   
   HistÃ³rico da conversa (Ãºltimas 10, mais recente primeiro):
   [...]
   
   Mensagem atual do cliente:
   {mensagemRecebida}
   ```

---

### 2. **Modificar: `src/lib/utils/ollama.ts`**

**MudanÃ§as necessÃ¡rias:**

1. **Nova funÃ§Ã£o para resposta JSON:**
```typescript
interface OllamaJSONResponse {
  status_sugerido: string;
  resposta: string;
}

export async function generateOllamaJSONResponse(
  prompt: string,
  modelName: string = 'llama3.1:8b'
): Promise<OllamaJSONResponse>
```

**CaracterÃ­sticas:**
- Envia prompt completo (sem histÃ³rico separado)
- ForÃ§a formato JSON na resposta
- Faz parsing e validaÃ§Ã£o do JSON retornado
- Trata erros de parsing

---

### 3. **Modificar: `src/app/api/webhook/route.ts`**

**MudanÃ§as:**
- Substituir `handleAutoReply` atual
- Usar `generatePrompt()` para criar prompt estruturado
- Usar `generateOllamaJSONResponse()` para obter resposta
- Logar JSON no console (por enquanto)
- Extrair apenas `resposta` para enviar via WhatsApp

---

## ğŸ”„ Fluxo Completo

```
1. Mensagem recebida via WhatsApp
   â†“
2. processMessage() - Salva mensagem no banco
   â†“
3. generatePrompt()
   - Busca AtendimentoAI
   - Busca Contato (status atual)
   - Busca histÃ³rico (Ãºltimas 10 mensagens)
   - Monta prompt estruturado
   â†“
4. generateOllamaJSONResponse()
   - Envia prompt para Ollama
   - Recebe JSON: { status_sugerido, resposta }
   â†“
5. Log JSON no console
   â†“
6. Extrai campo "resposta"
   â†“
7. sendWhatsAppMessage() - Envia resposta
   â†“
8. saveSentMessage() - Salva resposta no banco
```

---

## ğŸ“Š Estrutura do Prompt Gerado

```
{promptBase do AtendimentoAI}

Comportamento esperado para o status do contato que enviou a mensagem:

{objetoAtendimentoAI[statusAtual]}
Exemplo: se status = "Aberta", usa objetoAtendimentoAI.aberta

VocÃª deve analisar a conversa e decidir se o status deve mudar para um dos seguintes:
['Aberta', 'QualificaÃ§Ã£o', 'Proposta', 'NegociaÃ§Ã£o', 'Fechamento', 'Perdida']

Caso considere que o status deve mudar, retorne o novo status.

Retorne SOMENTE em JSON no formato:
{
  "status_sugerido": "",
  "resposta": ""
}

HistÃ³rico da conversa:
  mensagem do cliente: "..."
  mensagem do assistente: "..."
  mensagem do cliente: "..."
  ...

Mensagem atual do cliente:
{mensagemRecebida}
```

---

## âš ï¸ Pontos de AtenÃ§Ã£o

### 1. **Status do Contato**
- O modelo Contato jÃ¡ tem enum com os status corretos
- Status padrÃ£o: 'Aberta'
- Status possÃ­veis: ['Aberta', 'QualificaÃ§Ã£o', 'Proposta', 'NegociaÃ§Ã£o', 'Fechamento', 'Perdida']

### 2. **HistÃ³rico de Mensagens**
- Ãšltimas 10 mensagens (ou menos se nÃ£o tiver)
- Ordem: **mais recente primeiro** (diferente do atual que Ã© mais antiga primeiro)
- Formato: "mensagem do cliente:" ou "mensagem do assistente:"
- Apenas mensagens de texto

### 3. **Resposta JSON do Ollama**
- Ollama pode nÃ£o retornar JSON puro sempre
- Precisa de instruÃ§Ãµes claras no prompt
- Precisa fazer parsing seguro com fallback
- Validar campos obrigatÃ³rios

### 4. **Mapeamento Status â†’ Campo AtendimentoAI**
- Status "Aberta" â†’ campo `aberta`
- Status "QualificaÃ§Ã£o" â†’ campo `qualificaÃ§Ã£o`
- Status "Proposta" â†’ campo `proposta`
- Status "NegociaÃ§Ã£o" â†’ campo `negociaÃ§Ã£o`
- Status "Fechamento" â†’ campo `fechamento`
- Status "Perdida" â†’ campo `perdida`

---

## ğŸš€ Ordem de ImplementaÃ§Ã£o

1. âœ… Criar `generatePrompt.ts` - Gerador de prompt estruturado
2. âœ… Modificar `ollama.ts` - Adicionar funÃ§Ã£o JSON response
3. âœ… Modificar `webhook/route.ts` - Integrar novo fluxo
4. âœ… Testar com mensagem real
5. â­ï¸ Futuro: Implementar atualizaÃ§Ã£o automÃ¡tica de status

---

## ğŸ§ª Casos de Teste

### Caso 1: Primeira Mensagem
- Contato novo
- Status: "Aberta" (padrÃ£o)
- HistÃ³rico vazio ou com apenas 1 mensagem
- Deve gerar prompt correto
- Deve retornar resposta de saudaÃ§Ã£o

### Caso 2: Conversa em Andamento
- Contato existente
- Status: "QualificaÃ§Ã£o"
- HistÃ³rico com 5+ mensagens
- Deve incluir histÃ³rico completo
- Deve usar comportamento de "QualificaÃ§Ã£o"

### Caso 3: MudanÃ§a de Status
- Cliente demonstra interesse em proposta
- Status atual: "QualificaÃ§Ã£o"
- Deve sugerir: "Proposta" ou "NegociaÃ§Ã£o"
- Resposta deve seguir novo status sugerido

---

## ğŸ“Œ Notas Importantes

1. **Por enquanto:** Apenas logar JSON no console
2. **Futuro:** Implementar atualizaÃ§Ã£o automÃ¡tica de status do contato
3. **Futuro:** Criar interface para visualizar/editar prompts
4. **SeguranÃ§a:** Validar sempre os dados do banco antes de usar

---

## âœ… Checklist de ImplementaÃ§Ã£o

- [ ] Criar arquivo `src/lib/utils/generatePrompt.ts`
- [ ] Implementar busca de AtendimentoAI
- [ ] Implementar busca de Contato e status
- [ ] Implementar formataÃ§Ã£o de histÃ³rico
- [ ] Implementar montagem de prompt
- [ ] Adicionar funÃ§Ã£o JSON response em `ollama.ts`
- [ ] Modificar `webhook/route.ts` para usar novo sistema
- [ ] Adicionar logs detalhados
- [ ] Testar com diferentes status
- [ ] Testar com histÃ³rico vazio
- [ ] Testar com histÃ³rico completo

---

## ğŸ¯ Resultado Esperado

Ao receber uma mensagem:
1. Console mostra o JSON completo:
   ```json
   {
     "status_sugerido": "QualificaÃ§Ã£o",
     "resposta": "Que tipo de site vocÃª estÃ¡ precisando?"
   }
   ```
2. Apenas o campo `resposta` Ã© enviado via WhatsApp
3. Resposta Ã© salva no banco normalmente
4. Sistema estÃ¡ pronto para futura implementaÃ§Ã£o de atualizaÃ§Ã£o de status

